# MNIST-DCGAN: Generating Digits with Deep Convolutional GANs
### Overview ğŸ‘€
Welcome to the MNIST-DCGAN project! In this project, we use a Deep Convolutional Generative Adversarial Network (DCGAN) to generate handwritten digits based on the MNIST dataset. This project demonstrates how GANs can be employed to create new, realistic-looking images from random noise, further expanding understanding of generative models.

### Dataset ğŸ“¦
The dataset used is the MNIST dataset, which consists of 60,000 28x28 grayscale images of handwritten digits. The dataset is preprocessed to scale pixel values between -1 and 1, optimizing it for the generator and discriminator in the GAN.

### Architecture ğŸ—ï¸
Generator: The generator is designed to transform random noise (latent space) into images resembling handwritten digits.
Discriminator: The discriminator aims to distinguish between real images from the MNIST dataset and fake images produced by the generator.
Loss Function: Binary cross-entropy is used to compute the loss for both the generator and discriminator.

### Objective ğŸ¯
The goal of this project is to train a DCGAN capable of generating new digit images indistinguishable from real MNIST data, while exploring GAN architecture and improving generative model techniques.

### Training ğŸ”„
Batch size: 256
Epochs: 100
Optimizer: Adam with a learning rate of 0.00001
Noise dimension: 100 (the size of the random input vector to the generator)

### Visualization ğŸ“Š
During training, images generated by the DCGAN are visualized to observe the modelâ€™s learning progress.

### Evaluation ğŸ“
The model is evaluated based on its ability to generate realistic images. Visual inspection is often used to determine whether the generated digits resemble those from the MNIST dataset.

### Credits ğŸ’¡
This project is inspired by research in generative models and is implemented using TensorFlow and Keras. Special thanks to the open-source community for their contributions!
