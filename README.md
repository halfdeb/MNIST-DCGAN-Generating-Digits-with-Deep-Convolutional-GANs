# MNIST-DCGAN: Generating Digits with Deep Convolutional GANs
### Overview 👀
Welcome to the MNIST-DCGAN project! In this project, we use a Deep Convolutional Generative Adversarial Network (DCGAN) to generate handwritten digits based on the MNIST dataset. This project demonstrates how GANs can be employed to create new, realistic-looking images from random noise, further expanding understanding of generative models.

### Dataset 📦
The dataset used is the MNIST dataset, which consists of 60,000 28x28 grayscale images of handwritten digits. The dataset is preprocessed to scale pixel values between -1 and 1, optimizing it for the generator and discriminator in the GAN.

### Architecture 🏗️
Generator: The generator is designed to transform random noise (latent space) into images resembling handwritten digits.
Discriminator: The discriminator aims to distinguish between real images from the MNIST dataset and fake images produced by the generator.
Loss Function: Binary cross-entropy is used to compute the loss for both the generator and discriminator.

### Objective 🎯
The goal of this project is to train a DCGAN capable of generating new digit images indistinguishable from real MNIST data, while exploring GAN architecture and improving generative model techniques.

### Training 🔄
Batch size: 256
Epochs: 100
Optimizer: Adam with a learning rate of 0.00001
Noise dimension: 100 (the size of the random input vector to the generator)

### Visualization 📊
During training, images generated by the DCGAN are visualized to observe the model’s learning progress.

### Evaluation 📏
The model is evaluated based on its ability to generate realistic images. Visual inspection is often used to determine whether the generated digits resemble those from the MNIST dataset.

### Credits 💡
This project is inspired by research in generative models and is implemented using TensorFlow and Keras. Special thanks to the open-source community for their contributions!
